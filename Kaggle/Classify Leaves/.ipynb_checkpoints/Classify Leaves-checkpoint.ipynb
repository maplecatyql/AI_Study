{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_frame = pd.read_csv('./train.csv')\n",
    "labels_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454282f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves_labels = sorted(list(set(labels_frame['label'])))\n",
    "num_classes = len(leaves_labels)\n",
    "leaves_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc188988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2num = dict(zip(leaves_labels, range(num_classes)))\n",
    "class2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num2class = { v : k for k, v in class2num.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffdd184",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeavesDataset(Dataset):\n",
    "    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height=224, resize_width=224):\n",
    "        self.resize_height = resize_height\n",
    "        self.resize_width = resize_width\n",
    "        self.file_path = file_path\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        self.data_len = len(self.data_info.index) - 1\n",
    "        self.train_len = int(self.data_len * (1 - valid_ratio))\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.train_image = np.asarray(self.data_info.iloc[1:self.train_len, 0])\n",
    "            self.train_label = np.asarray(self.data_info.iloc[1:self.train_len, 1])\n",
    "            self.image_arr = self.train_image\n",
    "            self.label_arr = self.train_label\n",
    "        elif mode == 'valid':\n",
    "            self.valid_image = np.asarray(self.data_info.iloc[self.train_len:, 0])\n",
    "            self.valid_label = np.asarray(self.data_info.iloc[self.train_len:, 1])\n",
    "            self.image_arr = self.valid_image\n",
    "            self.label_arr = self.valid_label\n",
    "        elif mode == 'test':\n",
    "            self.test_image = np.asarray(self.data_info.iloc[1:, 0])\n",
    "            self.image_arr = self.test_image\n",
    "        \n",
    "        self.real_len = len(self.image_arr)\n",
    "        \n",
    "        print('Finished reading the {} set of Leaves Dataset ({} samples found)'.format(mode, self.real_len))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        single_image_name = self.image_arr[index]\n",
    "        img_as_img = Image.open(self.file_path + single_image_name)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            train_augs = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((self.resize_height, self.resize_width)),\n",
    "                torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "            \n",
    "        else:\n",
    "            valid_test_augs = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize((self.resize_height, self.resize_width)),\n",
    "                torchvision.transforms.ToTensor()\n",
    "            ])\n",
    "            \n",
    "        if self.mode == 'train':\n",
    "            img_as_img = train_augs(img_as_img)\n",
    "        else:\n",
    "            img_as_img = valid_test_augs(img_as_img)\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return img_as_img\n",
    "        else:\n",
    "            label = self.image_arr[index]\n",
    "            number_label = class2num[label]\n",
    "            return img_as_img, number_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.real_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d69bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train.csv'\n",
    "test_path = './test.csv'\n",
    "image_path = './' # csv文件中已经images的路径了，因此这里只到上一级目录\n",
    "\n",
    "train_dataset = LeavesDataset(train_path, image_path, 'train')\n",
    "valid_dataset = LeavesDataset(train_path, image_path, 'valid')\n",
    "test_dataset = LeavesDataset(test_path, image_path, 'test')\n",
    "\n",
    "print(train_dataset)\n",
    "print(valid_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=5\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=5\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13216a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im_convert(tensor):\n",
    "#     \"\"\" 展示数据\"\"\"\n",
    "    \n",
    "# #     image = tensor.to(\"cpu\").clone().detach()\n",
    "#     image = image.numpy().squeeze() # squeeze() 把维度为1的数组剪切，使得正常画图\n",
    "#     image = image.transpose(1,2,0) # imshow() 是 h w c 而image是 c h w\n",
    "#     image = image.clip(0, 1)\n",
    "\n",
    "#     return image\n",
    "\n",
    "# fig=plt.figure(figsize=(20, 12))\n",
    "# columns = 4  # 2*4=8 正好是一个batch_size的大小\n",
    "# rows = 2\n",
    "\n",
    "# dataiter = iter(valid_loader)\n",
    "# inputs, classes = dataiter.next()\n",
    "\n",
    "# for idx in range (columns*rows):\n",
    "#     ax = fig.add_subplot(rows, columns, idx+1, xticks=[], yticks=[])\n",
    "#     ax.set_title(num2class[int(classes[idx])])\n",
    "#     plt.imshow(im_convert(inputs[idx]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90aef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\" 模型冻结 \"\"\"\n",
    "    if feature_extracting:\n",
    "        model = model\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "            \n",
    "def res_model(num_classes, feature_extracting=False, use_pretrained=True):\n",
    "    model_ft = torchvision.models.resnet34(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extracting)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-3\n",
    "num_epoch = 30\n",
    "model_path = './models/classify_leaves_v1.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6fb197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = res_model(num_classes)\n",
    "model = model.to(device)\n",
    "model.device = device\n",
    "\n",
    "# 损失函数 - 交叉熵\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# 迭代次数\n",
    "n_epochs = num_epoch\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(n_epochs):\n",
    "    # ----------------- Train -----------------\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(imgs)\n",
    "        l = loss(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        train_loss.append(l.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ----------------- Validation -----------------\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for batch in tqdm(valid_loader):\n",
    "        imgs, labels = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        l_v = loss(logits, labels.to(device))\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        valid_loss.append(l_v.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print('saving model with acc {:.3f}'.format(best_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039c3af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
